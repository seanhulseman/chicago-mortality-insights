{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a343a50",
   "metadata": {},
   "source": [
    "## refined LDA Topic Modeling on full primary cause\n",
    "Credit where credit is due! Selva Prabhakaran, https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4d6f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in CLI:\n",
    "# pip install spacy\n",
    "# pip install pyLDAvis\n",
    "# python3 -m spacy download 'en_core_web_sm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51abad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import spacy\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3695662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../susan/data/cleaned_data_31OCT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceb77bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stem the words\n",
    "# I'm not lemmatizing b/c we don't have many verbs\n",
    "# and when iI tried before it messed up non-verbs commonly found in our dataset, \n",
    "# like turning 'wound' into 'wind' and 'left' into 'leav'\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in stop_words and len(token) > 2:\n",
    "            result.append(ps.stem(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd40b094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test it's functioning as expected\n",
    "\n",
    "doc_sample = df[df.index == 10_001].values[0][8]\n",
    "\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "\n",
    "print('\\nstemmed document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e13df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the 'primary_cause' column\n",
    "\n",
    "data_words = df['primary_cause'].map(preprocess).tolist()\n",
    "\n",
    "#data_words = preproc.tolist()\n",
    "\n",
    "#print(data_words[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73de8b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build bigram and trigram models\n",
    "# bigrams worked better so I didn't end up using trigrams\n",
    "\n",
    "bigram = gensim.models.Phrases(data_words, min_count=1, threshold=1) \n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=1)  \n",
    "\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0196d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build bigram and trigram functions\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ab13ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make bigrams and trigram\n",
    "data_words_bigrams = make_bigrams(data_words)\n",
    "data_words_trigrams = make_trigrams(data_words) # bigrams may be more useful\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c393531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_words_bigrams)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_words_bigrams\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4211bb2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check the processing with human-readable format of corpus (term, frequency in doc)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[25:30]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34977055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build the LDA model 1\n",
    "\n",
    "# lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "#                                            id2word=id2word,\n",
    "#                                            num_topics=4,\n",
    "#                                            random_state=42,\n",
    "#                                            update_every=1,\n",
    "#                                            chunksize=100,\n",
    "#                                            passes=10,\n",
    "#                                            alpha='auto',\n",
    "#                                            per_word_topics=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5ea1c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Print keywords in each topic\n",
    "# pprint(lda_model.print_topics())\n",
    "# doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0aa8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute perplexity, a measure of how good the model is. The lower the better.\n",
    "\n",
    "# print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  \n",
    "\n",
    "# # Compute coherence score, a measure of how well the elements of the topic support each other\n",
    "\n",
    "# coherence_model_lda = CoherenceModel(model=lda_model, texts=data_words_bigrams, dictionary=id2word, coherence='c_v')\n",
    "# coherence_lda = coherence_model_lda.get_coherence()\n",
    "# print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7157cfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model 2\n",
    "\n",
    "lda_model2 = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=5,\n",
    "                                           random_state=42,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=3000,\n",
    "                                           passes=20,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7e978c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print keywords in each topic\n",
    "pprint(lda_model2.print_topics())\n",
    "doc_lda = lda_model2[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40e0fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model2, corpus, id2word)\n",
    "\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e5b44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute perplexity, a measure of how good the model is. The lower the better.\n",
    "\n",
    "print('\\nPerplexity: ', lda_model2.log_perplexity(corpus))  \n",
    "\n",
    "# Compute coherence score, a measure of how well the elements of the topic support each other\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=lda_model2, texts=data_words_bigrams, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf111306",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model2.get_document_topics(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c72a5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b2966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_topic_finder(corpus):\n",
    "    best_topic_tuples = []\n",
    "    for i in range(0, len(corpus)):\n",
    "        best_topic = (sorted(lda_model2.get_document_topics(corpus[i]), key=lambda x: x[1], reverse=True))[0][0]\n",
    "        perc_topic = (sorted(lda_model2.get_document_topics(corpus[i]), key=lambda x: x[1], reverse=True))[0][1]\n",
    "        best_topic_tuple = (best_topic, perc_topic)\n",
    "        best_topic_tuples.append(best_topic_tuple)\n",
    "    return best_topic_tuples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328af8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_topic(corpus):\n",
    "    best_topic_list = []\n",
    "    for i in range(0, len(corpus)):\n",
    "        best_topic = (sorted(lda_model2.get_document_topics(corpus[i]), key=lambda x: x[1], reverse=True))[0][0]\n",
    "        best_topic_list.append(best_topic)\n",
    "    return best_topic_list\n",
    "\n",
    "best_topic_column = best_topic(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae2fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_perc(corpus):\n",
    "    topic_perc_list = []\n",
    "    for i in range(0, len(corpus)):\n",
    "        perc_topic = (sorted(lda_model2.get_document_topics(corpus[i]), key=lambda x: x[1], reverse=True))[0][1]\n",
    "        topic_perc_list.append(perc_topic)\n",
    "    return topic_perc_list\n",
    "\n",
    "topic_perc_column = topic_perc(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515759ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['long_topic'] = lda_model2.get_document_topics(corpus)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae8c50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['best_topic_num'] = best_topic_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4606905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['best_topic_name'] = df['best_topic_num'].map({0:'gunshot_wound_suicide', 1:'gunshot_wounds_homicide', 2:'vehicle_collision', 3:'drug_overdose', 4:'miscellaneous'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9fdbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['best_topic_perc'] = topic_perc_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2f2b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4945aec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['primary_cause_line_a', 'primary_cause_line_b', 'long_topic', 'best_topic', 'best_topic_name','best_topic_perc', ]].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a631eec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dec6e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619ea32a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ac70d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76a1bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit: https://stackoverflow.com/questions/70295773/extract-topic-scores-for-documents-lda-gensim-python\n",
    "\n",
    "# Find dominant topic in each doc\n",
    "\n",
    "##dominant topic for each document\n",
    "def format_topics_sentences(ldamodel=lda_model, \n",
    "                            corpus=corpus, \n",
    "                            texts=data_words, \n",
    "                            n=1):\n",
    "    \"\"\"\n",
    "    A function for extracting a number of dominant topics for a given document\n",
    "    using an existing LDA model\n",
    "    \"\"\"\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            # we use range here to iterate over the n parameter\n",
    "            if j in range(n):  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(\n",
    "                    # and also use the i value here to get the document label\n",
    "                    pd.Series([int(i), int(topic_num), round(prop_topic, 4), topic_keywords]),\n",
    "                    ignore_index=True,\n",
    "                )\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = [\"Document\", \"Dominant_Topic\", \"Perc_Contribution\", \"Topic_Keywords\"]\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    text_col = [texts[int(i)] for i in sent_topics_df.Document.tolist()]\n",
    "    contents = pd.Series(text_col, name='original_texts')\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return sent_topics_df\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data_words, n=1)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f6c395",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(lda_model[corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bcff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts, common_corpus, common_dictionary\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# train a quick lda model using the common _corpus, _dictionary and _texts from gensim\n",
    "optimal_model = LdaModel(common_corpus, id2word=common_dictionary, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2463e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eef7c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words_bigrams[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc203bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit: https://stackoverflow.com/questions/70295773/extract-topic-scores-for-documents-lda-gensim-python\n",
    "\n",
    "##dominant topic for each document\n",
    "def format_topics_sentences(ldamodel=optimal_model, \n",
    "                            corpus=common_corpus, \n",
    "                            texts=common_texts, \n",
    "                            n=1):\n",
    "    \"\"\"\n",
    "    A function for extracting a number of dominant topics for a given document\n",
    "    using an existing LDA model\n",
    "    \"\"\"\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            # we use range here to iterate over the n parameter\n",
    "            if j in range(n):  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = pd.concat([sent_topics_df, \n",
    "                                            (pd.Series([int(i), int(topic_num), round(prop_topic, 4), topic_keywords])).to_frame().T], \n",
    "                                           ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "    sent_topics_df.columns = [\"Document\", \"Dominant_Topic\", \"Perc_Contribution\", \"Topic_Keywords\"]\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    text_col = [texts[int(i)] for i in sent_topics_df.Document.tolist()]\n",
    "    contents = pd.Series(text_col, name='original_texts')\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return sent_topics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe9a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_topics_sentences(ldamodel=optimal_model, corpus=common_corpus, texts=common_texts, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59c2b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "##dominant topic for each document\n",
    "def format_topics_sentences(ldamodel=lda_model, \n",
    "                            corpus=corpus, \n",
    "                            texts=data_words_bigrams, \n",
    "                            n=1):\n",
    "    \"\"\"\n",
    "    A function for extracting a number of dominant topics for a given document\n",
    "    using an existing LDA model\n",
    "    \"\"\"\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            # we use range here to iterate over the n parameter\n",
    "            if j in range(n):  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = pd.concat([sent_topics_df, \n",
    "                                            (pd.Series([int(i), int(topic_num), round(prop_topic, 4), topic_keywords])).to_frame().T], \n",
    "                                           ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "    sent_topics_df.columns = [\"Document\", \"Dominant_Topic\", \"Perc_Contribution\", \"Topic_Keywords\"]\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    text_col = [texts[int(i)] for i in sent_topics_df.Document.tolist()]\n",
    "    contents = pd.Series(text_col, name='original_texts')\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return sent_topics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963afce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data_words_bigrams, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f267305c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8e9afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edea93d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d33e97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08193b28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1ff006",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
